{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106804,
     "status": "ok",
     "timestamp": 1766740307828,
     "user": {
      "displayName": "TrÃ­ Cao Minh",
      "userId": "13115819814062813479"
     },
     "user_tz": -420
    },
    "id": "hRZ1wvE8n-Wg",
    "outputId": "f55b9a65-c0f3-43f8-d0c1-730e7c258631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPU not available: Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}\n",
      "   XGBoost will use CPU\n",
      "================================================================================\n",
      "FLIGHT DELAY PREDICTION - OPTIMIZED ML PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Loading dataset...\n",
      "âœ… Dataset loaded: 539,383 rows, 9 columns\n",
      "\n",
      "ğŸ“Š First 5 rows:\n",
      "   id Airline  Flight AirportFrom AirportTo  DayOfWeek  Time  Length  Delay\n",
      "0   1      CO     269         SFO       IAH          3    15     205      1\n",
      "1   2      US    1558         PHX       CLT          3    15     222      1\n",
      "2   3      AA    2400         LAX       DFW          3    20     165      1\n",
      "3   4      AA    2466         SFO       DFW          3    20     195      1\n",
      "4   5      AS     108         ANC       SEA          3    30     202      0\n",
      "\n",
      "================================================================================\n",
      "ğŸ” Data Exploration\n",
      "================================================================================\n",
      "\n",
      "Target distribution:\n",
      "Delay\n",
      "0    299119\n",
      "1    240264\n",
      "Name: count, dtype: int64\n",
      "Delay rate: 44.54%\n",
      "Missing values: 0\n",
      "\n",
      "Numeric features (3): ['DayOfWeek', 'Time', 'Length']\n",
      "Categorical features (3): ['Airline', 'AirportFrom', 'AirportTo']\n",
      "\n",
      "================================================================================\n",
      "ğŸ—ï¸ Building preprocessing pipeline\n",
      "================================================================================\n",
      "\n",
      "âœ‚ï¸ Splitting data (train: 70%, val: 15%, test: 15%)...\n",
      "Training: 377,568 | Validation: 80,907 | Test: 80,908\n",
      "\n",
      "================================================================================\n",
      "ğŸ¤– Training Models\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Training: Logistic Regression\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Validation Results:\n",
      "  Accuracy  : 0.6458\n",
      "  Precision : 0.6336\n",
      "  Recall    : 0.4858\n",
      "  F1        : 0.5499\n",
      "  ROC-AUC   : 0.6907\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Training: Random Forest\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Validation Results:\n",
      "  Accuracy  : 0.6335\n",
      "  Precision : 0.7422\n",
      "  Recall    : 0.2715\n",
      "  F1        : 0.3975\n",
      "  ROC-AUC   : 0.6878\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Training: XGBoost\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Validation Results:\n",
      "  Accuracy  : 0.6600\n",
      "  Precision : 0.6828\n",
      "  Recall    : 0.4420\n",
      "  F1        : 0.5367\n",
      "  ROC-AUC   : 0.7084\n",
      "\n",
      "================================================================================\n",
      "ğŸ† Model Selection\n",
      "================================================================================\n",
      "\n",
      "Validation Performance:\n",
      "              Model  Accuracy  Precision   Recall       F1  ROC-AUC\n",
      "Logistic Regression  0.645840   0.633646 0.485779 0.549947 0.690672\n",
      "            XGBoost  0.659992   0.682796 0.442049 0.536659 0.708440\n",
      "      Random Forest  0.633480   0.742168 0.271484 0.397546 0.687786\n",
      "\n",
      "ğŸ¥‡ Best Model: Logistic Regression\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Final Test Set Evaluation\n",
      "================================================================================\n",
      "\n",
      "Logistic Regression - Test Set Performance:\n",
      "  Accuracy  : 0.6448\n",
      "  Precision : 0.6326\n",
      "  Recall    : 0.4834\n",
      "  F1        : 0.5481\n",
      "  ROC-AUC   : 0.6918\n",
      "\n",
      "Confusion Matrix:\n",
      "  [[TN=34750, FP=10118]\n",
      "   [FN=18617, TP=17423]]\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¾ Saving Model\n",
      "================================================================================\n",
      "âœ… Model saved: flight_delay_model.pkl\n",
      "âœ… Model info saved: model_info.json\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª Sample Prediction\n",
      "================================================================================\n",
      "\n",
      "Input: {'Airline': 'Southwest', 'AirportFrom': 'LAX', 'AirportTo': 'JFK', 'DayOfWeek': 5, 'Time': 1800, 'Length': 300}\n",
      "Prediction: âš ï¸ DELAYED\n",
      "Confidence: 74.5%\n",
      "\n",
      "================================================================================\n",
      "âœ… TRAINING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU availability\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import xgboost as xgb\n",
    "    XGB_OK = True\n",
    "    # Check if GPU is available\n",
    "    try:\n",
    "        # This will raise an error if CUDA is not available\n",
    "        xgb.XGBClassifier(tree_method='gpu_hist', n_estimators=1).fit([[0]], [0])\n",
    "        GPU_AVAILABLE = True\n",
    "        print(\"âœ… GPU detected and available for XGBoost\")\n",
    "    except Exception as e:\n",
    "        GPU_AVAILABLE = False\n",
    "        print(f\"âš ï¸ GPU not available: {e}\")\n",
    "        print(\"   XGBoost will use CPU\")\n",
    "except ImportError:\n",
    "    XGB_OK = False\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ XGBoost not found. Install with: pip install xgboost\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FLIGHT DELAY PREDICTION - OPTIMIZED ML PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD DATASET\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“ Loading dataset...\")\n",
    "\n",
    "url = \"https://drive.google.com/uc?export=download&id=1fd-oGGYVqy5EaqU2wL3dhHEFW-yFXZOa\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(url)\n",
    "    print(f\"âœ… Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "except (FileNotFoundError, pd.errors.ParserError) as e:\n",
    "    print(f\"âš ï¸ Error loading dataset: {e}\")\n",
    "    print(\"Creating synthetic data for demonstration...\\n\")\n",
    "\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "\n",
    "    airlines = ['Southwest', 'Delta', 'American', 'United', 'JetBlue']\n",
    "    airports = ['ATL', 'DFW', 'DEN', 'ORD', 'LAX', 'CLT', 'MCO']\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id': range(1, n_samples + 1),\n",
    "        'Airline': np.random.choice(airlines, n_samples),\n",
    "        'Flight': np.random.randint(100, 9999, n_samples),\n",
    "        'AirportFrom': np.random.choice(airports, n_samples),\n",
    "        'AirportTo': np.random.choice(airports, n_samples),\n",
    "        'DayOfWeek': np.random.randint(1, 8, n_samples),\n",
    "        'Time': np.random.randint(1, 2400, n_samples),\n",
    "        'Length': np.random.randint(30, 500, n_samples),\n",
    "        'Delay': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "    })\n",
    "    print(f\"âœ… Synthetic dataset: {df.shape[0]:,} rows\")\n",
    "\n",
    "print(\"\\nğŸ“Š First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ” Data Exploration\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find target column\n",
    "target_col = 'Delay'\n",
    "if target_col not in df.columns:\n",
    "    delay_cols = [col for col in df.columns if 'delay' in col.lower()]\n",
    "    if delay_cols:\n",
    "        target_col = delay_cols[0]\n",
    "        print(f\"Using '{target_col}' as target variable\")\n",
    "    else:\n",
    "        raise ValueError(\"Cannot find delay column!\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df[target_col].value_counts())\n",
    "print(f\"Delay rate: {df[target_col].mean():.2%}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Remove ID columns\n",
    "id_cols = ['id', 'Id', 'ID', 'Flight', 'flight']\n",
    "df = df.drop(columns=[col for col in id_cols if col in df.columns])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Removed: # Convert categorical features to 'category' dtype for XGBoost with enable_categorical=True\n",
    "# Removed: for col in categorical_features:\n",
    "# Removed:     X[col] = X[col].astype('category')\n",
    "\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: BUILD PREPROCESSING PIPELINE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ—ï¸ Building preprocessing pipeline\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))  # Keep sparse for memory\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: TRAIN-VALIDATION-TEST SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\nâœ‚ï¸ Splitting data (train: 70%, val: 15%, test: 15%)...\")\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 50% of temp = 15% val, 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]:,} | Validation: {X_val.shape[0]:,} | Test: {X_test.shape[0]:,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: DEFINE AND TRAIN MODELS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¤– Training Models\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,  # Reduced from 200\n",
    "        max_depth=10,       # Reduced from 15\n",
    "        min_samples_split=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "}\n",
    "\n",
    "# Add XGBoost with GPU if available\n",
    "if XGB_OK:\n",
    "    xgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss',\n",
    "        'early_stopping_rounds': 10,\n",
    "        'tree_method': 'gpu_hist' if GPU_AVAILABLE else 'hist'\n",
    "        # Removed 'enable_categorical': True as OneHotEncoder handles it\n",
    "    }\n",
    "\n",
    "    if GPU_AVAILABLE:\n",
    "        xgb_params['predictor'] = 'gpu_predictor'\n",
    "        print(\"ğŸš€ XGBoost configured for GPU acceleration\")\n",
    "\n",
    "    models['XGBoost'] = XGBClassifier(**xgb_params)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'â”€' * 80}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print('â”€' * 80)\n",
    "\n",
    "    if name == 'XGBoost' and XGB_OK:\n",
    "        # For XGBoost with early stopping, manually preprocess eval_set\n",
    "        # as pipeline.fit(classifier__eval_set) passes raw X_val.\n",
    "\n",
    "        # 1. Fit the ColumnTransformer (preprocessor) on training data only\n",
    "        fitted_preprocessor = preprocessor.fit(X_train)\n",
    "\n",
    "        # 2. Transform training and validation data using the fitted preprocessor\n",
    "        X_train_transformed = fitted_preprocessor.transform(X_train)\n",
    "        X_val_transformed = fitted_preprocessor.transform(X_val)\n",
    "\n",
    "        # 3. Fit the XGBoost classifier directly using transformed data and eval_set\n",
    "        model.fit(X_train_transformed, y_train,\n",
    "                  eval_set=[(X_val_transformed, y_val)],\n",
    "                  verbose=False) # verbose=False to suppress iteration output\n",
    "\n",
    "        # 4. Construct the final pipeline using the fitted preprocessor and the fitted XGBoost model\n",
    "        # This pipeline is ready for .predict() on new, raw data.\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', fitted_preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    else:\n",
    "        # For other models, or if not using early stopping with XGBoost, fit the pipeline normally.\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_proba = pipeline.predict_proba(X_val)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'Precision': precision_score(y_val, y_val_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_val, y_val_pred, zero_division=0),\n",
    "        'F1': f1_score(y_val, y_val_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    if y_val_proba is not None:\n",
    "        metrics['ROC-AUC'] = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "    results[name] = {'pipeline': pipeline, 'metrics': metrics}\n",
    "\n",
    "    print(f\"Validation Results:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name:10s}: {value:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: SELECT AND EVALUATE BEST MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ† Model Selection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare models by F1 Score (balanced metric for classification)\n",
    "comparison = pd.DataFrame([\n",
    "    {'Model': name, **result['metrics']}\n",
    "    for name, result in results.items()\n",
    "])\n",
    "comparison = comparison.sort_values('F1', ascending=False)\n",
    "\n",
    "print(\"\\nValidation Performance:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "best_model_name = comparison.iloc[0]['Model']\n",
    "best_pipeline = results[best_model_name]['pipeline']\n",
    "\n",
    "print(f\"\\nğŸ¥‡ Best Model: {best_model_name}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š Final Test Set Evaluation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "y_test_pred = best_pipeline.predict(X_test)\n",
    "y_test_proba = best_pipeline.predict_proba(X_test)[:, 1] if hasattr(best_pipeline.named_steps['classifier'], 'predict_proba') else None\n",
    "\n",
    "test_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'Precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "    'Recall': recall_score(y_test, y_test_pred, zero_division=0),\n",
    "    'F1': f1_score(y_test, y_test_pred, zero_division=0),\n",
    "}\n",
    "\n",
    "if y_test_proba is not None:\n",
    "    test_metrics['ROC-AUC'] = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\\n{best_model_name} - Test Set Performance:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"  {metric:10s}: {value:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  [[TN={cm[0,0]:5d}, FP={cm[0,1]:5d}]\")\n",
    "print(f\"   [FN={cm[1,0]:5d}, TP={cm[1,1]:5d}]]\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: SAVE MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ’¾ Saving Model\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_path = 'flight_delay_model.pkl'\n",
    "joblib.dump(best_pipeline, output_path, compress=3)\n",
    "print(f\"âœ… Model saved: {output_path}\")\n",
    "\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'test_metrics': test_metrics,\n",
    "    'features': {\n",
    "        'numeric': numeric_features,\n",
    "        'categorical': categorical_features\n",
    "    },\n",
    "    'gpu_used': GPU_AVAILABLE if best_model_name == 'XGBoost' else False,\n",
    "    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(\"âœ… Model info saved: model_info.json\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: EXAMPLE PREDICTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ§ª Sample Prediction\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample = pd.DataFrame([{\n",
    "    'Airline': 'Southwest',\n",
    "    'AirportFrom': 'LAX',\n",
    "    'AirportTo': 'JFK',\n",
    "    'DayOfWeek': 5,\n",
    "    'Time': 1800,\n",
    "    'Length': 300\n",
    "}])\n",
    "\n",
    "pred = best_pipeline.predict(sample)[0]\n",
    "proba = best_pipeline.predict_proba(sample)[0] if hasattr(best_pipeline.named_steps['classifier'], 'predict_proba') else None\n",
    "\n",
    "print(f\"\\nInput: {sample.to_dict('records')[0]}\")\n",
    "print(f\"Prediction: {'âš ï¸ DELAYED' if pred == 1 else 'âœ… ON TIME'}\")\n",
    "if proba is not None:\n",
    "    print(f\"Confidence: {proba[pred]:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… TRAINING COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOYPJeu4O1x15o0VWwUz/UM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
